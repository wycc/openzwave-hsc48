/* Run the C pre-processor over this file with one of the following defined
 * ELF - elf object files,
 * OUT - a.out object files,
 * BSDI - BSDI style a.out object files
 * SOL - Solaris style elf
 */

#define TYPE(a,b)       .type   a,b
#define SIZE(a,b)       .size   a,b

#if defined(OUT) || (defined(BSDI) && !defined(ELF))
#define ft_tab _ft_tab
#define fl_tab _fl_tab
#define it_tab _it_tab
#define il_tab _il_tab
#define aes_encrypt _aes_encrypt
#define aes_decrypt _aes_decrypt

#endif

#ifdef OUT
#define OK	1
#define ALIGN	4
#endif

#if defined(BSDI) && !defined(ELF)
#define OK              1
#define ALIGN           4
#undef SIZE
#undef TYPE
#define SIZE(a,b)
#define TYPE(a,b)
#endif

#if defined(ELF) || defined(SOL)
#define OK              1
#define ALIGN           32
#endif

#ifndef OK
You need to define one of
ELF - elf systems - linux-elf, NetBSD and DG-UX
OUT - a.out systems - linux-a.out and FreeBSD
SOL - solaris systems, which are elf with strange comment lines
BSDI - a.out with a very primative version of as.
#endif

/* Let the Assembler begin :-) */
	/* Don't even think of reading this code */
	/* It was automatically generated by aes-586.pl */
	/* Which is a perl program used to generate the x86 assember for */
	/* any of elf, a.out, BSDI, Win32, gaswin (for GNU as on Win32) or Solaris */
	/* eric <eay@cryptsoft.com> */

	.file	"aes-586.s"
	.version	"01.01"
gcc2_compiled.:
.text
	.align ALIGN
.globl aes_encrypt
	TYPE(aes_encrypt,@function)
aes_encrypt:
	/* save registers - this is actually faster than push/pop */
	subl	$24,		%esp
	movl	%ebp,		20(%esp)
	/* acquire the context information from param(2) */
	movl	36(%esp),	%ebp
	/* skipping tests that key sched is complete */
	movl	%ebx,		16(%esp)
	movl	%esi,		12(%esp)
	movl	%edi,		8(%esp)
	/* acquring input block from param(0) */
.L000strt:
	movl	28(%esp),	%ecx
	movl	516(%ebp),	%edx
	leal	16(%ebp),	%ebp
	/* load up the four columns */
	movl	(%ecx),		%eax
	movl	4(%ecx),	%ebx
	movl	8(%ecx),	%esi
	movl	12(%ecx),	%edi
	/* xor in first round key */
	xorl	-16(%ebp),	%eax
	xorl	-12(%ebp),	%ebx
	xorl	-8(%ebp),	%esi
	xorl	-4(%ebp),	%edi
	/* increment to next round key */
	subl	$10,		%edx
	je	.L001e10_rounds
	addl	$32,		%ebp
	subl	$2,		%edx
	je	.L002e12_rounds
	addl	$32,		%ebp
.L003e14_rounds:
	/* [fwd_rnd(-64, ft_tab)] */
	movl	%eax,		%ecx
	movl	%ebx,		(%esp)
	movl	%edi,		4(%esp)
	movzx	%al,		%edx
	movl	-64(%ebp),	%eax
	movl	-52(%ebp),	%edi
	xorl	ft_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	-60(%ebp),	%ebx
	xorl	1024+ft_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+ft_tab(,%ecx,4),%ebx
	movl	%esi,		%ecx
	movl	2048+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+ft_tab(,%ecx,4),%edi
	movzx	%dl,		%ecx
	xorl	-56(%ebp),	%esi
	xorl	ft_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+ft_tab(,%ecx,4),%eax
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+ft_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%ebx
	xorl	3072+ft_tab(,%ecx,4),%eax
	/* [fwd_rnd(-48, ft_tab)] */
	movl	%eax,		%ecx
	movl	%ebx,		(%esp)
	movl	%edi,		4(%esp)
	movzx	%al,		%edx
	movl	-48(%ebp),	%eax
	movl	-36(%ebp),	%edi
	xorl	ft_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	-44(%ebp),	%ebx
	xorl	1024+ft_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+ft_tab(,%ecx,4),%ebx
	movl	%esi,		%ecx
	movl	2048+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+ft_tab(,%ecx,4),%edi
	movzx	%dl,		%ecx
	xorl	-40(%ebp),	%esi
	xorl	ft_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+ft_tab(,%ecx,4),%eax
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+ft_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%ebx
	xorl	3072+ft_tab(,%ecx,4),%eax
.L002e12_rounds:
	/* [fwd_rnd(-32, ft_tab)] */
	movl	%eax,		%ecx
	movl	%ebx,		(%esp)
	movl	%edi,		4(%esp)
	movzx	%al,		%edx
	movl	-32(%ebp),	%eax
	movl	-20(%ebp),	%edi
	xorl	ft_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	-28(%ebp),	%ebx
	xorl	1024+ft_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+ft_tab(,%ecx,4),%ebx
	movl	%esi,		%ecx
	movl	2048+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+ft_tab(,%ecx,4),%edi
	movzx	%dl,		%ecx
	xorl	-24(%ebp),	%esi
	xorl	ft_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+ft_tab(,%ecx,4),%eax
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+ft_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%ebx
	xorl	3072+ft_tab(,%ecx,4),%eax
	/* [fwd_rnd(-16, ft_tab)] */
	movl	%eax,		%ecx
	movl	%ebx,		(%esp)
	movl	%edi,		4(%esp)
	movzx	%al,		%edx
	movl	-16(%ebp),	%eax
	movl	-4(%ebp),	%edi
	xorl	ft_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	-12(%ebp),	%ebx
	xorl	1024+ft_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+ft_tab(,%ecx,4),%ebx
	movl	%esi,		%ecx
	movl	2048+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+ft_tab(,%ecx,4),%edi
	movzx	%dl,		%ecx
	xorl	-8(%ebp),	%esi
	xorl	ft_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+ft_tab(,%ecx,4),%eax
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+ft_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%ebx
	xorl	3072+ft_tab(,%ecx,4),%eax
.L001e10_rounds:
	/* [fwd_rnd(0, ft_tab)] */
	movl	%eax,		%ecx
	movl	%ebx,		(%esp)
	movl	%edi,		4(%esp)
	movzx	%al,		%edx
	movl	(%ebp),		%eax
	movl	12(%ebp),	%edi
	xorl	ft_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	4(%ebp),	%ebx
	xorl	1024+ft_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+ft_tab(,%ecx,4),%ebx
	movl	%esi,		%ecx
	movl	2048+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+ft_tab(,%ecx,4),%edi
	movzx	%dl,		%ecx
	xorl	8(%ebp),	%esi
	xorl	ft_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+ft_tab(,%ecx,4),%eax
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+ft_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%ebx
	xorl	3072+ft_tab(,%ecx,4),%eax
	/* [fwd_rnd(16, ft_tab)] */
	movl	%eax,		%ecx
	movl	%ebx,		(%esp)
	movl	%edi,		4(%esp)
	movzx	%al,		%edx
	movl	16(%ebp),	%eax
	movl	28(%ebp),	%edi
	xorl	ft_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	20(%ebp),	%ebx
	xorl	1024+ft_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+ft_tab(,%ecx,4),%ebx
	movl	%esi,		%ecx
	movl	2048+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+ft_tab(,%ecx,4),%edi
	movzx	%dl,		%ecx
	xorl	24(%ebp),	%esi
	xorl	ft_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+ft_tab(,%ecx,4),%eax
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+ft_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%ebx
	xorl	3072+ft_tab(,%ecx,4),%eax
	/* [fwd_rnd(32, ft_tab)] */
	movl	%eax,		%ecx
	movl	%ebx,		(%esp)
	movl	%edi,		4(%esp)
	movzx	%al,		%edx
	movl	32(%ebp),	%eax
	movl	44(%ebp),	%edi
	xorl	ft_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	36(%ebp),	%ebx
	xorl	1024+ft_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+ft_tab(,%ecx,4),%ebx
	movl	%esi,		%ecx
	movl	2048+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+ft_tab(,%ecx,4),%edi
	movzx	%dl,		%ecx
	xorl	40(%ebp),	%esi
	xorl	ft_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+ft_tab(,%ecx,4),%eax
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+ft_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%ebx
	xorl	3072+ft_tab(,%ecx,4),%eax
	/* [fwd_rnd(48, ft_tab)] */
	movl	%eax,		%ecx
	movl	%ebx,		(%esp)
	movl	%edi,		4(%esp)
	movzx	%al,		%edx
	movl	48(%ebp),	%eax
	movl	60(%ebp),	%edi
	xorl	ft_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	52(%ebp),	%ebx
	xorl	1024+ft_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+ft_tab(,%ecx,4),%ebx
	movl	%esi,		%ecx
	movl	2048+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+ft_tab(,%ecx,4),%edi
	movzx	%dl,		%ecx
	xorl	56(%ebp),	%esi
	xorl	ft_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+ft_tab(,%ecx,4),%eax
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+ft_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%ebx
	xorl	3072+ft_tab(,%ecx,4),%eax
	/* [fwd_rnd(64, ft_tab)] */
	movl	%eax,		%ecx
	movl	%ebx,		(%esp)
	movl	%edi,		4(%esp)
	movzx	%al,		%edx
	movl	64(%ebp),	%eax
	movl	76(%ebp),	%edi
	xorl	ft_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	68(%ebp),	%ebx
	xorl	1024+ft_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+ft_tab(,%ecx,4),%ebx
	movl	%esi,		%ecx
	movl	2048+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+ft_tab(,%ecx,4),%edi
	movzx	%dl,		%ecx
	xorl	72(%ebp),	%esi
	xorl	ft_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+ft_tab(,%ecx,4),%eax
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+ft_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%ebx
	xorl	3072+ft_tab(,%ecx,4),%eax
	/* [fwd_rnd(80, ft_tab)] */
	movl	%eax,		%ecx
	movl	%ebx,		(%esp)
	movl	%edi,		4(%esp)
	movzx	%al,		%edx
	movl	80(%ebp),	%eax
	movl	92(%ebp),	%edi
	xorl	ft_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	84(%ebp),	%ebx
	xorl	1024+ft_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+ft_tab(,%ecx,4),%ebx
	movl	%esi,		%ecx
	movl	2048+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+ft_tab(,%ecx,4),%edi
	movzx	%dl,		%ecx
	xorl	88(%ebp),	%esi
	xorl	ft_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+ft_tab(,%ecx,4),%eax
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+ft_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%ebx
	xorl	3072+ft_tab(,%ecx,4),%eax
	/* [fwd_rnd(96, ft_tab)] */
	movl	%eax,		%ecx
	movl	%ebx,		(%esp)
	movl	%edi,		4(%esp)
	movzx	%al,		%edx
	movl	96(%ebp),	%eax
	movl	108(%ebp),	%edi
	xorl	ft_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	100(%ebp),	%ebx
	xorl	1024+ft_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+ft_tab(,%ecx,4),%ebx
	movl	%esi,		%ecx
	movl	2048+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+ft_tab(,%ecx,4),%edi
	movzx	%dl,		%ecx
	xorl	104(%ebp),	%esi
	xorl	ft_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+ft_tab(,%ecx,4),%eax
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+ft_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%ebx
	xorl	3072+ft_tab(,%ecx,4),%eax
	/* [fwd_rnd(112, ft_tab)] */
	movl	%eax,		%ecx
	movl	%ebx,		(%esp)
	movl	%edi,		4(%esp)
	movzx	%al,		%edx
	movl	112(%ebp),	%eax
	movl	124(%ebp),	%edi
	xorl	ft_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	116(%ebp),	%ebx
	xorl	1024+ft_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+ft_tab(,%ecx,4),%ebx
	movl	%esi,		%ecx
	movl	2048+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+ft_tab(,%ecx,4),%edi
	movzx	%dl,		%ecx
	xorl	120(%ebp),	%esi
	xorl	ft_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+ft_tab(,%ecx,4),%eax
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+ft_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%ebx
	xorl	3072+ft_tab(,%ecx,4),%eax
	/* [fwd_rnd(128, ft_tab)] */
	movl	%eax,		%ecx
	movl	%ebx,		(%esp)
	movl	%edi,		4(%esp)
	movzx	%al,		%edx
	movl	128(%ebp),	%eax
	movl	140(%ebp),	%edi
	xorl	ft_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	132(%ebp),	%ebx
	xorl	1024+ft_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+ft_tab(,%ecx,4),%ebx
	movl	%esi,		%ecx
	movl	2048+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+ft_tab(,%ecx,4),%edi
	movzx	%dl,		%ecx
	xorl	136(%ebp),	%esi
	xorl	ft_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+ft_tab(,%ecx,4),%eax
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+ft_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	ft_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+ft_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+ft_tab(,%edx,4),%ebx
	xorl	3072+ft_tab(,%ecx,4),%eax
	/* [fwd_rnd(144, fl_tab)] */
	movl	%eax,		%ecx
	movl	%ebx,		(%esp)
	movl	%edi,		4(%esp)
	movzx	%al,		%edx
	movl	144(%ebp),	%eax
	movl	156(%ebp),	%edi
	xorl	fl_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	148(%ebp),	%ebx
	xorl	1024+fl_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+fl_tab(,%ecx,4),%ebx
	movl	%esi,		%ecx
	movl	2048+fl_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	fl_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+fl_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+fl_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+fl_tab(,%ecx,4),%edi
	movzx	%dl,		%ecx
	xorl	152(%ebp),	%esi
	xorl	fl_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+fl_tab(,%ecx,4),%eax
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+fl_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+fl_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	fl_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+fl_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+fl_tab(,%edx,4),%ebx
	xorl	3072+fl_tab(,%ecx,4),%eax
	/* move results to output block */
	movl	32(%esp),	%ebp
	movl	%edi,		12(%ebp)
	movl	%esi,		8(%ebp)
	movl	%ebx,		4(%ebp)
	movl	%eax,		(%ebp)
	movl	$1,		%eax
	movl	8(%esp),	%edi
	movl	12(%esp),	%esi
	movl	16(%esp),	%ebx
.L004end:
	movl	20(%esp),	%ebp
	addl	$24,		%esp
	ret
.L_aes_encrypt_end:
	SIZE(aes_encrypt,.L_aes_encrypt_end-aes_encrypt)
.ident	"desasm.pl"
.text
	.align ALIGN
.globl aes_decrypt
	TYPE(aes_decrypt,@function)
aes_decrypt:
	/* save registers - this is actually faster than push/pop */
	subl	$24,		%esp
	movl	%ebp,		20(%esp)
	/* acquire the context information from param(2) */
	movl	36(%esp),	%ebp
	/* skipping tests that key sched is complete */
	movl	%ebx,		16(%esp)
	movl	%esi,		12(%esp)
	movl	%edi,		8(%esp)
	/* acquring input block from param(0) */
.L005strt:
	movl	28(%esp),	%ecx
	movl	516(%ebp),	%edx
	/* table offset is a multiple of 16, hence double lea */
	leal	272(%ebp,%edx,8),%ebp
	leal	(%ebp,%edx,8),	%ebp
	/* load up the four columns */
	movl	(%ecx),		%eax
	movl	4(%ecx),	%ebx
	movl	8(%ecx),	%esi
	movl	12(%ecx),	%edi
	/* xor in first round key */
	xorl	-16(%ebp),	%eax
	xorl	-12(%ebp),	%ebx
	xorl	-8(%ebp),	%esi
	xorl	-4(%ebp),	%edi
	/* increment to next round key */
	movl	36(%esp),	%ebp
	leal	400(%ebp),	%ebp
	subl	$10,		%edx
	je	.L006e10_rounds
	subl	$2,		%edx
	je	.L007e12_rounds
.L008e14_rounds:
	/* [inv_rnd(64, it_tab)] */
	movzx	%al,		%edx
	movl	%ebx,		(%esp)
	movl	%eax,		%ecx
	movl	64(%ebp),	%eax
	movl	%edi,		4(%esp)
	movl	68(%ebp),	%ebx
	xorl	it_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	76(%ebp),	%edi
	xorl	1024+it_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+it_tab(,%ecx,4),%edi
	movl	%esi,		%ecx
	movl	2048+it_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+it_tab(,%ecx,4),%ebx
	movzx	%dl,		%ecx
	xorl	72(%ebp),	%esi
	xorl	it_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+it_tab(,%ecx,4),%esi
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+it_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%ebx
	xorl	3072+it_tab(,%ecx,4),%esi
	/* [inv_rnd(48, it_tab)] */
	movzx	%al,		%edx
	movl	%ebx,		(%esp)
	movl	%eax,		%ecx
	movl	48(%ebp),	%eax
	movl	%edi,		4(%esp)
	movl	52(%ebp),	%ebx
	xorl	it_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	60(%ebp),	%edi
	xorl	1024+it_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+it_tab(,%ecx,4),%edi
	movl	%esi,		%ecx
	movl	2048+it_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+it_tab(,%ecx,4),%ebx
	movzx	%dl,		%ecx
	xorl	56(%ebp),	%esi
	xorl	it_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+it_tab(,%ecx,4),%esi
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+it_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%ebx
	xorl	3072+it_tab(,%ecx,4),%esi
.L007e12_rounds:
	/* [inv_rnd(32, it_tab)] */
	movzx	%al,		%edx
	movl	%ebx,		(%esp)
	movl	%eax,		%ecx
	movl	32(%ebp),	%eax
	movl	%edi,		4(%esp)
	movl	36(%ebp),	%ebx
	xorl	it_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	44(%ebp),	%edi
	xorl	1024+it_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+it_tab(,%ecx,4),%edi
	movl	%esi,		%ecx
	movl	2048+it_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+it_tab(,%ecx,4),%ebx
	movzx	%dl,		%ecx
	xorl	40(%ebp),	%esi
	xorl	it_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+it_tab(,%ecx,4),%esi
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+it_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%ebx
	xorl	3072+it_tab(,%ecx,4),%esi
	/* [inv_rnd(16, it_tab)] */
	movzx	%al,		%edx
	movl	%ebx,		(%esp)
	movl	%eax,		%ecx
	movl	16(%ebp),	%eax
	movl	%edi,		4(%esp)
	movl	20(%ebp),	%ebx
	xorl	it_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	28(%ebp),	%edi
	xorl	1024+it_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+it_tab(,%ecx,4),%edi
	movl	%esi,		%ecx
	movl	2048+it_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+it_tab(,%ecx,4),%ebx
	movzx	%dl,		%ecx
	xorl	24(%ebp),	%esi
	xorl	it_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+it_tab(,%ecx,4),%esi
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+it_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%ebx
	xorl	3072+it_tab(,%ecx,4),%esi
.L006e10_rounds:
	/* [inv_rnd(0, it_tab)] */
	movzx	%al,		%edx
	movl	%ebx,		(%esp)
	movl	%eax,		%ecx
	movl	(%ebp),		%eax
	movl	%edi,		4(%esp)
	movl	4(%ebp),	%ebx
	xorl	it_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	12(%ebp),	%edi
	xorl	1024+it_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+it_tab(,%ecx,4),%edi
	movl	%esi,		%ecx
	movl	2048+it_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+it_tab(,%ecx,4),%ebx
	movzx	%dl,		%ecx
	xorl	8(%ebp),	%esi
	xorl	it_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+it_tab(,%ecx,4),%esi
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+it_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%ebx
	xorl	3072+it_tab(,%ecx,4),%esi
	/* [inv_rnd(-16, it_tab)] */
	movzx	%al,		%edx
	movl	%ebx,		(%esp)
	movl	%eax,		%ecx
	movl	-16(%ebp),	%eax
	movl	%edi,		4(%esp)
	movl	-12(%ebp),	%ebx
	xorl	it_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	-4(%ebp),	%edi
	xorl	1024+it_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+it_tab(,%ecx,4),%edi
	movl	%esi,		%ecx
	movl	2048+it_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+it_tab(,%ecx,4),%ebx
	movzx	%dl,		%ecx
	xorl	-8(%ebp),	%esi
	xorl	it_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+it_tab(,%ecx,4),%esi
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+it_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%ebx
	xorl	3072+it_tab(,%ecx,4),%esi
	/* [inv_rnd(-32, it_tab)] */
	movzx	%al,		%edx
	movl	%ebx,		(%esp)
	movl	%eax,		%ecx
	movl	-32(%ebp),	%eax
	movl	%edi,		4(%esp)
	movl	-28(%ebp),	%ebx
	xorl	it_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	-20(%ebp),	%edi
	xorl	1024+it_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+it_tab(,%ecx,4),%edi
	movl	%esi,		%ecx
	movl	2048+it_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+it_tab(,%ecx,4),%ebx
	movzx	%dl,		%ecx
	xorl	-24(%ebp),	%esi
	xorl	it_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+it_tab(,%ecx,4),%esi
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+it_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%ebx
	xorl	3072+it_tab(,%ecx,4),%esi
	/* [inv_rnd(-48, it_tab)] */
	movzx	%al,		%edx
	movl	%ebx,		(%esp)
	movl	%eax,		%ecx
	movl	-48(%ebp),	%eax
	movl	%edi,		4(%esp)
	movl	-44(%ebp),	%ebx
	xorl	it_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	-36(%ebp),	%edi
	xorl	1024+it_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+it_tab(,%ecx,4),%edi
	movl	%esi,		%ecx
	movl	2048+it_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+it_tab(,%ecx,4),%ebx
	movzx	%dl,		%ecx
	xorl	-40(%ebp),	%esi
	xorl	it_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+it_tab(,%ecx,4),%esi
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+it_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%ebx
	xorl	3072+it_tab(,%ecx,4),%esi
	/* [inv_rnd(-64, it_tab)] */
	movzx	%al,		%edx
	movl	%ebx,		(%esp)
	movl	%eax,		%ecx
	movl	-64(%ebp),	%eax
	movl	%edi,		4(%esp)
	movl	-60(%ebp),	%ebx
	xorl	it_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	-52(%ebp),	%edi
	xorl	1024+it_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+it_tab(,%ecx,4),%edi
	movl	%esi,		%ecx
	movl	2048+it_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+it_tab(,%ecx,4),%ebx
	movzx	%dl,		%ecx
	xorl	-56(%ebp),	%esi
	xorl	it_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+it_tab(,%ecx,4),%esi
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+it_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%ebx
	xorl	3072+it_tab(,%ecx,4),%esi
	/* [inv_rnd(-80, it_tab)] */
	movzx	%al,		%edx
	movl	%ebx,		(%esp)
	movl	%eax,		%ecx
	movl	-80(%ebp),	%eax
	movl	%edi,		4(%esp)
	movl	-76(%ebp),	%ebx
	xorl	it_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	-68(%ebp),	%edi
	xorl	1024+it_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+it_tab(,%ecx,4),%edi
	movl	%esi,		%ecx
	movl	2048+it_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+it_tab(,%ecx,4),%ebx
	movzx	%dl,		%ecx
	xorl	-72(%ebp),	%esi
	xorl	it_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+it_tab(,%ecx,4),%esi
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+it_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%ebx
	xorl	3072+it_tab(,%ecx,4),%esi
	/* [inv_rnd(-96, it_tab)] */
	movzx	%al,		%edx
	movl	%ebx,		(%esp)
	movl	%eax,		%ecx
	movl	-96(%ebp),	%eax
	movl	%edi,		4(%esp)
	movl	-92(%ebp),	%ebx
	xorl	it_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	-84(%ebp),	%edi
	xorl	1024+it_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+it_tab(,%ecx,4),%edi
	movl	%esi,		%ecx
	movl	2048+it_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+it_tab(,%ecx,4),%ebx
	movzx	%dl,		%ecx
	xorl	-88(%ebp),	%esi
	xorl	it_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+it_tab(,%ecx,4),%esi
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+it_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%ebx
	xorl	3072+it_tab(,%ecx,4),%esi
	/* [inv_rnd(-112, it_tab)] */
	movzx	%al,		%edx
	movl	%ebx,		(%esp)
	movl	%eax,		%ecx
	movl	-112(%ebp),	%eax
	movl	%edi,		4(%esp)
	movl	-108(%ebp),	%ebx
	xorl	it_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	-100(%ebp),	%edi
	xorl	1024+it_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+it_tab(,%ecx,4),%edi
	movl	%esi,		%ecx
	movl	2048+it_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+it_tab(,%ecx,4),%ebx
	movzx	%dl,		%ecx
	xorl	-104(%ebp),	%esi
	xorl	it_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+it_tab(,%ecx,4),%esi
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+it_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%ebx
	xorl	3072+it_tab(,%ecx,4),%esi
	/* [inv_rnd(-128, it_tab)] */
	movzx	%al,		%edx
	movl	%ebx,		(%esp)
	movl	%eax,		%ecx
	movl	-128(%ebp),	%eax
	movl	%edi,		4(%esp)
	movl	-124(%ebp),	%ebx
	xorl	it_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	-116(%ebp),	%edi
	xorl	1024+it_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+it_tab(,%ecx,4),%edi
	movl	%esi,		%ecx
	movl	2048+it_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+it_tab(,%ecx,4),%ebx
	movzx	%dl,		%ecx
	xorl	-120(%ebp),	%esi
	xorl	it_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+it_tab(,%ecx,4),%esi
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+it_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	xorl	it_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+it_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+it_tab(,%edx,4),%ebx
	xorl	3072+it_tab(,%ecx,4),%esi
	/* [inv_rnd(-144, il_tab)] */
	movzx	%al,		%edx
	movl	%ebx,		(%esp)
	movl	%eax,		%ecx
	movl	-144(%ebp),	%eax
	movl	%edi,		4(%esp)
	movl	-140(%ebp),	%ebx
	xorl	il_tab(,%edx,4),%eax
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	movl	-132(%ebp),	%edi
	xorl	1024+il_tab(,%edx,4),%ebx
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	3072+il_tab(,%ecx,4),%edi
	movl	%esi,		%ecx
	movl	2048+il_tab(,%edx,4),%esi
	movzx	%cl,		%edx
	xorl	il_tab(,%edx,4),%esi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+il_tab(,%edx,4),%edi
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+il_tab(,%edx,4),%eax
	movl	(%esp),		%edx
	xorl	3072+il_tab(,%ecx,4),%ebx
	movzx	%dl,		%ecx
	xorl	-136(%ebp),	%esi
	xorl	il_tab(,%ecx,4),%ebx
	movzx	%dh,		%ecx
	shrl	$16,		%edx
	xorl	1024+il_tab(,%ecx,4),%esi
	movzx	%dl,		%ecx
	movzx	%dh,		%edx
	xorl	2048+il_tab(,%ecx,4),%edi
	movl	4(%esp),	%ecx
	xorl	3072+il_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	xorl	il_tab(,%edx,4),%edi
	movzx	%ch,		%edx
	shrl	$16,		%ecx
	xorl	1024+il_tab(,%edx,4),%eax
	movzx	%cl,		%edx
	movzx	%ch,		%ecx
	xorl	2048+il_tab(,%edx,4),%ebx
	xorl	3072+il_tab(,%ecx,4),%esi
	/* move results to output block */
	movl	32(%esp),	%ebp
	movl	%edi,		12(%ebp)
	movl	%esi,		8(%ebp)
	movl	%ebx,		4(%ebp)
	movl	%eax,		(%ebp)
	movl	$1,		%eax
	movl	8(%esp),	%edi
	movl	12(%esp),	%esi
	movl	16(%esp),	%ebx
.L009end:
	movl	20(%esp),	%ebp
	addl	$24,		%esp
	ret
.L_aes_decrypt_end:
	SIZE(aes_decrypt,.L_aes_decrypt_end-aes_decrypt)
.ident	"desasm.pl"
